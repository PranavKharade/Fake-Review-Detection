{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b287ab56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading Original Data... ---\n",
      "--- Augmenting Data with a Large, Diverse Set of Genuine Reviews ---\n",
      "Total reviews after large augmentation: 1220\n",
      "\n",
      "--- Data Preprocessing Complete ---\n",
      "\n",
      "--- Starting Final Improvement: Re-training on Augmented Data ---\n",
      "WARNING:tensorflow:From d:\\Fake_Review_Detector\\venv\\Lib\\site-packages\\tf_keras\\src\\backend.py:1400: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['predictions.decoder.weight', 'predictions.dense.bias', 'predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.bias', 'predictions.dense.weight', 'predictions.LayerNorm.weight']\n",
      "- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFAlbertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training on the best dataset...\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:From d:\\Fake_Review_Detector\\venv\\Lib\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:From d:\\Fake_Review_Detector\\venv\\Lib\\site-packages\\tf_keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "110/110 [==============================] - 408s 4s/step - loss: 0.6017 - accuracy: 0.6868 - val_loss: 0.5138 - val_accuracy: 0.7857\n",
      "Epoch 2/2\n",
      "110/110 [==============================] - 423s 4s/step - loss: 0.4333 - accuracy: 0.8200 - val_loss: 0.5636 - val_accuracy: 0.7551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Fake_Review_Detector\\venv\\Lib\\site-packages\\transformers\\generation\\tf_utils.py:465: UserWarning: `seed_generator` is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\"`seed_generator` is deprecated and will be removed in a future version.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Improvement Complete! New model saved as 'fake_review_model_final.keras' ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import AlbertTokenizer, TFAlbertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tf_keras\n",
    "\n",
    "# --- Phase 1: Load Original Data ---\n",
    "print(\"--- Loading Original Data... ---\")\n",
    "# *** THE FIX IS HERE: Pointing to the likely nested folder ***\n",
    "base_path = 'D:/Fake_Review_Detector/op_spam_v1.4/op_spam_v1.4'\n",
    "\n",
    "reviews = []\n",
    "labels = []\n",
    "for label_type in ['deceptive_from_MTurk', 'truthful_from_TripAdvisor']:\n",
    "    for polarity in ['positive_polarity', 'negative_polarity']:\n",
    "        path = os.path.join(base_path, polarity, label_type)\n",
    "        files = glob.glob(os.path.join(path, 'fold*', '*.txt'))\n",
    "        for file_path in files:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                reviews.append(f.read())\n",
    "                labels.append(1 if 'deceptive' in label_type else 0)\n",
    "\n",
    "# --- Robustness Check ---\n",
    "if not reviews:\n",
    "    raise FileNotFoundError(\n",
    "        f\"CRITICAL ERROR: No original review files were found.\\n\"\n",
    "        f\"Please double-check your 'base_path'. It is currently set to: '{base_path}'\\n\"\n",
    "        f\"The correct path MUST point to the folder that contains the 'positive_polarity' and 'negative_polarity' folders.\"\n",
    "    )\n",
    "# --- End of Check ---\n",
    "\n",
    "df = pd.DataFrame({'review': reviews, 'label': labels})\n",
    "\n",
    "# --- DATA AUGMENTATION STEP ---\n",
    "print(\"--- Augmenting Data with a Large, Diverse Set of Genuine Reviews ---\")\n",
    "new_genuine_reviews = [\n",
    "    # Positive & Detailed\n",
    "    \"The room was spacious and the view of the city was breathtaking. The staff went above and beyond to make our anniversary special. Absolutely worth the price.\",\n",
    "    \"From the moment we checked in, the service was impeccable. The concierge gave us fantastic dinner recommendations. The bed was one of the most comfortable I've ever slept in.\",\n",
    "    # Balanced\n",
    "    \"The pool area was fantastic and the kids loved it. The room was a bit smaller than we expected, but it was very clean. A solid choice for a a family trip.\",\n",
    "    \"Location is unbeatable, right in the heart of everything. The downside is that it can be a bit noisy at night. The room itself was modern and well-maintained.\",\n",
    "    # Negative & Detailed (The kind our model gets wrong)\n",
    "    \"A complete disaster. Our flight was delayed and we arrived late, but the front desk had given our room away. We had to wait an hour for them to find us another, smaller room. No apology was offered.\",\n",
    "    \"Do not stay here. The pictures online are completely misleading. The carpet was stained, there was mold in the shower, and the whole place smelled like smoke. We checked out after one night.\",\n",
    "    # Short & Simple\n",
    "    \"Great place, very clean.\",\n",
    "    \"It was okay. Nothing special.\",\n",
    "    \"Wouldn't recommend.\",\n",
    "    \"Perfect for a quick business trip.\",\n",
    "    # More emotional but genuine reviews\n",
    "    \"I was so excited for this stay and it was a huge letdown. The service was so slow it felt like they forgot we were there. Ruined our weekend.\",\n",
    "    \"This was the best hotel experience I have ever had! I felt like royalty. The spa was heavenly and the food was divine. I cannot wait to come back!\",\n",
    "    \"Just a warning to others: the hidden 'resort fee' is a scam. It added an extra $50 per night to our bill for amenities we never even used. Very deceptive.\",\n",
    "    \"The staff here are the kindest people you will ever meet. My husband fell ill and they were so helpful and compassionate. They truly cared. I am so grateful.\",\n",
    "    # Neutral/Descriptive\n",
    "    \"The hotel is located about a 15-minute walk from the main train station. The room had a desk, a small fridge, and a safe. The bathroom was functional.\",\n",
    "    \"Check-in is at 3 PM. They have an airport shuttle that runs every hour. The on-site restaurant serves breakfast and dinner.\",\n",
    "    \"This is a standard business hotel. It does everything you need it to. The location is good for the convention center, the rooms are functional, and the gym is adequate.\",\n",
    "    \"We had a few issues. The key card stopped working twice. The shower had low water pressure. It wasn't a terrible stay, but it could have been better.\",\n",
    "    \"The view from our balcony was incredible. We could see the entire coastline. The room itself was a bit dated, but that view made up for everything.\",\n",
    "    \"Overall a positive experience. The hotel is pet-friendly which was a huge plus for us. They even provided a water bowl for our dog.\"\n",
    "]\n",
    "new_data = pd.DataFrame({\n",
    "    'review': new_genuine_reviews,\n",
    "    'label': [0] * len(new_genuine_reviews) # Label all as Genuine\n",
    "})\n",
    "df = pd.concat([df, new_data], ignore_index=True)\n",
    "# --- End of Augmentation ---\n",
    "\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(f\"Total reviews after large augmentation: {len(df)}\\n\")\n",
    "\n",
    "\n",
    "# --- Phase 2: Preprocessing ---\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    return text\n",
    "df['cleaned_review'] = df['review'].apply(clean_text)\n",
    "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "tokenized_data = tokenizer(\n",
    "    df['cleaned_review'].tolist(), padding='max_length', truncation=True, return_tensors='np', max_length=256\n",
    ")\n",
    "input_ids = tokenized_data['input_ids']\n",
    "attention_mask = tokenized_data['attention_mask']\n",
    "labels = np.array(df['label'].values)\n",
    "print(\"--- Data Preprocessing Complete ---\\n\")\n",
    "\n",
    "\n",
    "# --- PHASE 3: Re-training on the BEST Dataset ---\n",
    "print(\"--- Starting Final Improvement: Re-training on Augmented Data ---\")\n",
    "X_train_ids, X_test_ids, X_train_mask, X_test_mask, y_train, y_test = train_test_split(\n",
    "    input_ids, attention_mask, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "def create_model():\n",
    "    input_ids_layer = tf.keras.layers.Input(shape=(256,), dtype=tf.int32, name='input_ids')\n",
    "    attention_mask_layer = tf.keras.layers.Input(shape=(256,), dtype=tf.int32, name='attention_mask')\n",
    "    albert_model = TFAlbertModel.from_pretrained('albert-base-v2', from_pt=True)\n",
    "    albert_outputs = albert_model(input_ids_layer, attention_mask=attention_mask_layer)\n",
    "    sequence_output = albert_outputs.last_hidden_state\n",
    "    bilstm_layer = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64))(sequence_output)\n",
    "    output_layer = tf.keras.layers.Dense(1, activation='sigmoid')(bilstm_layer)\n",
    "    model = tf.keras.Model(inputs=[input_ids_layer, attention_mask_layer], outputs=output_layer)\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(\"Starting training on the best dataset...\")\n",
    "history = model.fit(\n",
    "    [X_train_ids, X_train_mask],\n",
    "    y_train,\n",
    "    epochs=2,\n",
    "    batch_size=8, # Using a small batch size for stability\n",
    "    validation_split=0.1\n",
    ")\n",
    "\n",
    "model_save_path = 'fake_review_model_final.keras'\n",
    "model.save(model_save_path)\n",
    "print(f\"\\n--- Final Improvement Complete! New model saved as '{model_save_path}' ---\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

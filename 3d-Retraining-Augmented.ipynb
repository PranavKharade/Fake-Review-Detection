{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49b974a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Fake_Review_Detector\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Fake_Review_Detector\\venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "--- Loading Original Data... ---\n",
      "--- Augmenting Data with New Genuine Reviews ---\n",
      "Total reviews after augmentation: 1205\n",
      "\n",
      "--- Data Preprocessing Complete ---\n",
      "\n",
      "--- Starting Improvement 3: Re-training on Augmented Data ---\n",
      "WARNING:tensorflow:From d:\\Fake_Review_Detector\\venv\\Lib\\site-packages\\tf_keras\\src\\backend.py:1400: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['predictions.bias', 'predictions.dense.bias', 'predictions.LayerNorm.weight', 'predictions.dense.weight', 'predictions.decoder.bias', 'predictions.decoder.weight', 'predictions.LayerNorm.bias']\n",
      "- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFAlbertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:From d:\\Fake_Review_Detector\\venv\\Lib\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:From d:\\Fake_Review_Detector\\venv\\Lib\\site-packages\\tf_keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import AlbertTokenizer, TFAlbertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tf_keras\n",
    "\n",
    "# --- Phase 1: Load Original Data ---\n",
    "print(\"--- Loading Original Data... ---\")\n",
    "base_path = 'D:/Fake_Review_Detector/op_spam_v1.4/op_spam_v1.4'\n",
    "\n",
    "reviews = []\n",
    "labels = []\n",
    "for label_type in ['deceptive_from_MTurk', 'truthful_from_TripAdvisor']:\n",
    "    for polarity in ['positive_polarity', 'negative_polarity']:\n",
    "        path = os.path.join(base_path, polarity, label_type)\n",
    "        files = glob.glob(os.path.join(path, 'fold*', '*.txt'))\n",
    "        for file_path in files:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                reviews.append(f.read())\n",
    "                labels.append(1 if 'deceptive' in label_type else 0)\n",
    "\n",
    "if not reviews:\n",
    "    raise FileNotFoundError(\n",
    "        f\"CRITICAL ERROR: No original review files were found.\\n\"\n",
    "        f\"Please double-check your 'base_path'. It is currently set to: '{base_path}'\"\n",
    "    )\n",
    "\n",
    "df = pd.DataFrame({'review': reviews, 'label': labels})\n",
    "\n",
    "# --- DATA AUGMENTATION STEP ---\n",
    "print(\"--- Augmenting Data with New Genuine Reviews ---\")\n",
    "new_genuine_reviews = [\n",
    "    \"The pool area was fantastic and the kids loved it. The room was a bit smaller than we expected from the photos, but it was very clean and the beds were comfortable. A solid choice for a family trip.\",\n",
    "    \"I really enjoyed my stay. The check-in process was smooth and the staff were incredibly professional. My only issue was that the Wi-Fi in my room was very slow and unreliable.\",\n",
    "    \"The restaurant downstairs was terrible - overpriced and slow service. However, I have to say the room itself was quiet and comfortable, which is the most important thing. I'd probably stay here again but eat somewhere else.\",\n",
    "    \"This is a standard business hotel. It does everything you need it to do efficiently. The location is good for the convention center, the rooms are functional, and the gym is adequate. Nothing special, but very reliable.\",\n",
    "    \"We had a few issues during our stay. The key card for our room stopped working twice, and we had to go down to the lobby to get it fixed. The shower also had very low water pressure. It wasn't a terrible stay, but it could have been better.\"\n",
    "]\n",
    "new_data = pd.DataFrame({\n",
    "    'review': new_genuine_reviews,\n",
    "    'label': [0] * len(new_genuine_reviews)\n",
    "})\n",
    "df = pd.concat([df, new_data], ignore_index=True)\n",
    "# --- End of Augmentation ---\n",
    "\n",
    "# Shuffle the combined dataset\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(f\"Total reviews after augmentation: {len(df)}\\n\")\n",
    "\n",
    "\n",
    "# --- Phase 2: Preprocessing ---\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    return text\n",
    "df['cleaned_review'] = df['review'].apply(clean_text)\n",
    "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "tokenized_data = tokenizer(\n",
    "    df['cleaned_review'].tolist(), padding='max_length', truncation=True, return_tensors='np', max_length=256\n",
    ")\n",
    "input_ids = tokenized_data['input_ids']\n",
    "attention_mask = tokenized_data['attention_mask']\n",
    "labels = np.array(df['label'].values)\n",
    "print(\"--- Data Preprocessing Complete ---\\n\")\n",
    "\n",
    "\n",
    "# --- PHASE 3: Re-training on Augmented Data ---\n",
    "print(\"--- Starting Improvement 3: Re-training on Augmented Data ---\")\n",
    "X_train_ids, X_test_ids, X_train_mask, X_test_mask, y_train, y_test = train_test_split(\n",
    "    input_ids, attention_mask, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "def create_model():\n",
    "    input_ids_layer = tf.keras.layers.Input(shape=(256,), dtype=tf.int32, name='input_ids')\n",
    "    # *** THIS LINE IS NOW CORRECTED ***\n",
    "    attention_mask_layer = tf.keras.layers.Input(shape=(256,), dtype=tf.int32, name='attention_mask')\n",
    "    albert_model = TFAlbertModel.from_pretrained('albert-base-v2', from_pt=True)\n",
    "    albert_outputs = albert_model(input_ids_layer, attention_mask=attention_mask_layer)\n",
    "    sequence_output = albert_outputs.last_hidden_state\n",
    "    bilstm_layer = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64))(sequence_output)\n",
    "    output_layer = tf.keras.layers.Dense(1, activation='sigmoid')(bilstm_layer)\n",
    "    model = tf.keras.Model(inputs=[input_ids_layer, attention_mask_layer], outputs=output_layer)\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(\"Starting training...\")\n",
    "history = model.fit(\n",
    "    [X_train_ids, X_train_mask],\n",
    "    y_train,\n",
    "    epochs=2,\n",
    "    batch_size=8, # Using a smaller batch size to prevent memory crashes\n",
    "    validation_split=0.1\n",
    ")\n",
    "\n",
    "model_save_path = 'fake_review_model_v4.keras'\n",
    "model.save(model_save_path)\n",
    "print(f\"\\n--- Improvement Step 3 Complete! New model saved as '{model_save_path}' ---\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

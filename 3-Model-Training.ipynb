{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d307c6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Fake_Review_Detector\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Fake_Review_Detector\\venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "--- Script Started ---\n",
      "--- Loading and Preprocessing Data... ---\n",
      "WARNING: Directory not found, skipping: D:/Fake_Review_Detector/op_spam_v1.4/op_spam_v1.4\\negative_polarity\\truthful_from_TripAdvisor\n",
      "Successfully loaded 1200 reviews.\n",
      "Text cleaning complete.\n",
      "Loading tokenizer...\n",
      "Tokenizing text (this may take a moment)...\n",
      "--- Data Loading and Preprocessing Complete ---\n",
      "\n",
      "--- Starting Phase 3: Model Building & Training ---\n",
      "\n",
      "Creating the ALBERT-BiLSTM model...\n",
      "WARNING:tensorflow:From d:\\Fake_Review_Detector\\venv\\Lib\\site-packages\\tf_keras\\src\\backend.py:1400: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertModel: ['predictions.dense.bias', 'predictions.decoder.bias', 'predictions.bias', 'predictions.dense.weight', 'predictions.LayerNorm.weight', 'predictions.decoder.weight', 'predictions.LayerNorm.bias']\n",
      "- This IS expected if you are initializing TFAlbertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFAlbertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFAlbertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created successfully.\n",
      "\n",
      "Compiling the model...\n",
      "Model compiled successfully.\n",
      "\n",
      "Starting model training (this will take several minutes)...\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:From d:\\Fake_Review_Detector\\venv\\Lib\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:From d:\\Fake_Review_Detector\\venv\\Lib\\site-packages\\tf_keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "54/54 [==============================] - 517s 9s/step - loss: 0.6030 - accuracy: 0.6898 - val_loss: 0.5385 - val_accuracy: 0.6979\n",
      "Epoch 2/3\n",
      "54/54 [==============================] - 502s 9s/step - loss: 0.5492 - accuracy: 0.7280 - val_loss: 0.4567 - val_accuracy: 0.8229\n",
      "Epoch 3/3\n",
      "54/54 [==============================] - 606s 11s/step - loss: 0.5253 - accuracy: 0.7639 - val_loss: 0.4985 - val_accuracy: 0.7812\n",
      "\n",
      "Model training complete!\n",
      "\n",
      "Saving the trained model to 'fake_review_model.keras'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Fake_Review_Detector\\venv\\Lib\\site-packages\\transformers\\generation\\tf_utils.py:465: UserWarning: `seed_generator` is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\"`seed_generator` is deprecated and will be removed in a future version.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully.\n",
      "\n",
      "--- Phase 3 Complete! You can now run the web application. ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "from transformers import AlbertTokenizer, TFAlbertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tf_keras # Ensure tf_keras is imported\n",
    "\n",
    "print(\"--- Script Started ---\")\n",
    "\n",
    "# --- Phase 1 & 2: Load and Preprocess Data ---\n",
    "print(\"--- Loading and Preprocessing Data... ---\")\n",
    "try:\n",
    "    # Make sure this path is correct for your D: drive\n",
    "    base_path = 'D:/Fake_Review_Detector/op_spam_v1.4/op_spam_v1.4'\n",
    "\n",
    "    reviews = []\n",
    "    labels = []\n",
    "    # This loop goes through all the folders and reads the text files\n",
    "    for label_type in ['deceptive_from_MTurk', 'truthful_from_TripAdvisor']:\n",
    "        for polarity in ['positive_polarity', 'negative_polarity']:\n",
    "            path = os.path.join(base_path, polarity, label_type)\n",
    "            if not os.path.isdir(path):\n",
    "                print(f\"WARNING: Directory not found, skipping: {path}\")\n",
    "                continue\n",
    "            files = glob.glob(os.path.join(path, 'fold*', '*.txt'))\n",
    "            for file_path in files:\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    reviews.append(f.read())\n",
    "                    labels.append(1 if 'deceptive' in label_type else 0)\n",
    "    \n",
    "    if not reviews:\n",
    "        raise FileNotFoundError(f\"No review files were found. Please check your base_path: '{base_path}'\")\n",
    "\n",
    "    df = pd.DataFrame({'review': reviews, 'label': labels})\n",
    "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    print(f\"Successfully loaded {len(df)} reviews.\")\n",
    "\n",
    "    # Clean text\n",
    "    def clean_text(text):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "        return text\n",
    "    df['cleaned_review'] = df['review'].apply(clean_text)\n",
    "    print(\"Text cleaning complete.\")\n",
    "\n",
    "    # Tokenize text\n",
    "    print(\"Loading tokenizer...\")\n",
    "    tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "    print(\"Tokenizing text (this may take a moment)...\")\n",
    "    tokenized_data = tokenizer(\n",
    "        df['cleaned_review'].tolist(),\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='np',\n",
    "        max_length=256\n",
    "    )\n",
    "    input_ids = tokenized_data['input_ids']\n",
    "    attention_mask = tokenized_data['attention_mask']\n",
    "    labels = np.array(df['label'].values)\n",
    "    print(\"--- Data Loading and Preprocessing Complete ---\\n\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"\\n--- AN ERROR OCCURRED DURING DATA PREPARATION ---\")\n",
    "    print(e)\n",
    "    # Stop the script if data loading fails\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- PHASE 3: MODEL BUILDING AND TRAINING ---\n",
    "print(\"--- Starting Phase 3: Model Building & Training ---\\n\")\n",
    "\n",
    "# 1. Split the data\n",
    "X_train_ids, X_test_ids, X_train_mask, X_test_mask, y_train, y_test = train_test_split(\n",
    "    input_ids, attention_mask, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 2. Build the Model\n",
    "def create_model():\n",
    "    input_ids_layer = tf.keras.layers.Input(shape=(256,), dtype=tf.int32, name='input_ids')\n",
    "    attention_mask_layer = tf.keras.layers.Input(shape=(256,), dtype=tf.int32, name='attention_mask')\n",
    "    \n",
    "    # We load the PyTorch weights and convert them, which requires torch to be installed\n",
    "    albert_model = TFAlbertModel.from_pretrained('albert-base-v2', from_pt=True)\n",
    "    albert_outputs = albert_model(input_ids_layer, attention_mask=attention_mask_layer)\n",
    "    sequence_output = albert_outputs.last_hidden_state\n",
    "    \n",
    "    bilstm_layer = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64))(sequence_output)\n",
    "    output_layer = tf.keras.layers.Dense(1, activation='sigmoid')(bilstm_layer)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[input_ids_layer, attention_mask_layer], outputs=output_layer)\n",
    "    return model\n",
    "\n",
    "print(\"Creating the ALBERT-BiLSTM model...\")\n",
    "model = create_model()\n",
    "print(\"Model created successfully.\\n\")\n",
    "\n",
    "# 3. Compile the Model\n",
    "print(\"Compiling the model...\")\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "print(\"Model compiled successfully.\\n\")\n",
    "\n",
    "# 4. Train the Model\n",
    "print(\"Starting model training (this will take several minutes)...\")\n",
    "history = model.fit(\n",
    "    [X_train_ids, X_train_mask],\n",
    "    y_train,\n",
    "    epochs=3,\n",
    "    batch_size=16,\n",
    "    validation_split=0.1\n",
    ")\n",
    "print(\"\\nModel training complete!\\n\")\n",
    "\n",
    "# 5. Save the Trained Model\n",
    "print(\"Saving the trained model to 'fake_review_model.keras'...\")\n",
    "model.save('fake_review_model.keras')\n",
    "print(\"Model saved successfully.\")\n",
    "print(\"\\n--- Phase 3 Complete! You can now run the web application. ---\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
